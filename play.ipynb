{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d10cecca-6791-4779-bc96-48b929ce01ef",
   "metadata": {},
   "source": [
    "# Ver jugar a un modelo de Super Mario preentrenado\n",
    "\n",
    "https://github.com/jorgecasase/mariobrosplay-windows-gym-RL\n",
    "\n",
    "Este notebook permite cargar y observar cómo juega un modelo de Super Mario preentrenado. Utiliza un entorno personalizado basado en OpenAI Gym, junto con varias optimizaciones específicas para juegos retro.\n",
    "\n",
    "## Requisitos\n",
    "1. Haber seguido los pasos del entorno virutal con conda de mi github\n",
    "\n",
    "2. Un modelo preentrenado debe estar disponible en el archivo `trained_mario.chkpt`. (celda 9)\n",
    "   - Si no tienes un modelo preentrenado, puedes entrenarlo siguiendo el tutorial en el siguiente enlace:\n",
    "     [Mario RL con PyTorch - Entrenamiento en 400 episodios](https://github.com/pedroconcejero/deep_learning_2024/blob/main/mario_RL_pytorch_tutorial_400_episodes_save_every_1e4.ipynb)\n",
    "     - o puedes usar el de github\n",
    "2. Asegúrate de tener instaladas todas las dependencias necesarias, incluidas `gym`, `gym_super_mario_bros`, y `torch`.\n",
    "\n",
    "Una vez cumplidos los requisitos, puedes cargar el modelo y observar su rendimiento en el entorno.\n",
    "\n",
    "Nota: este notebook está adaptado para ser ejecutado en windows nativo, no funciona en colab ni en macos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6b009a-1cc6-423b-a991-85eedf6bca79",
   "metadata": {},
   "source": [
    "## Importación de modulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3551dfb9-25bb-4523-9f2c-65f370725985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de módulos necesarios\n",
    "import random, datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# Importación de librerías para Gym y Super Mario\n",
    "import gym\n",
    "import gym_super_mario_bros\n",
    "from gym.wrappers import FrameStack, GrayScaleObservation, TransformObservation\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "\n",
    "# Importación de módulos personalizados\n",
    "from metrics import MetricLogger\n",
    "from agent import Mario\n",
    "from wrappers import ResizeObservation, SkipFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c749d5e-e651-447c-869b-5bd556789812",
   "metadata": {},
   "source": [
    "## Creación del entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2362891-1ace-4374-a7f9-21ddcb709f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación del entorno base de Super Mario\n",
    "env = gym_super_mario_bros.make('SuperMarioBros-1-1-v0')\n",
    "\n",
    "# Configuración del espacio de acciones (Joypad)\n",
    "env = JoypadSpace(\n",
    "    env,\n",
    "    [['right'],  # Acción 1: caminar a la derecha\n",
    "    ['right', 'A']]  # Acción 2: caminar a la derecha y saltar\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978f5aaa-819d-49aa-995f-bb858abcf433",
   "metadata": {},
   "source": [
    "## Aplicación de wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418ee118-42a5-4b70-b0bc-0a9eeb56cb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicación de wrappers para modificar el entorno\n",
    "env = SkipFrame(env, skip=4)  # Saltar frames para mejorar el rendimiento\n",
    "env = GrayScaleObservation(env, keep_dim=False)  # Convertir observaciones a escala de grises\n",
    "env = ResizeObservation(env, shape=84)  # Redimensionar observaciones a 84x84 píxeles\n",
    "env = TransformObservation(env, f=lambda x: x / 255.)  # Normalizar observaciones\n",
    "env = FrameStack(env, num_stack=4)  # Apilar 4 frames consecutivos\n",
    "\n",
    "# Reiniciar el entorno para comenzar\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24d60df-2569-405b-a9de-79217071f9a7",
   "metadata": {},
   "source": [
    "## Cargar modelo preentrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6344dfa9-9815-425a-b692-04ca2daf33ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración del directorio de guardado para puntos de control y métricas\n",
    "save_dir = Path('checkpoints') / datetime.datetime.now().strftime('%Y-%m-%dT%H-%M-%S')\n",
    "save_dir.mkdir(parents=True)  # Crear el directorio si no existe\n",
    "\n",
    "# Inicialización del agente Mario con un punto de control preentrenado **AQUI CARGAS TU MODELO**\n",
    "checkpoint = Path('mario_net_13.chkpt')\n",
    "mario = Mario(state_dim=(4, 84, 84), action_dim=env.action_space.n, save_dir=save_dir, checkpoint=checkpoint)\n",
    "\n",
    "# Fijar la tasa de exploración al mínimo\n",
    "mario.exploration_rate = mario.exploration_rate_min\n",
    "\n",
    "# Inicialización del registro de métricas\n",
    "logger = MetricLogger(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63268b9-4e6b-49e7-8091-6d115c88387d",
   "metadata": {},
   "source": [
    "## Verlo jugar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbaed87-f499-44dc-94e0-de35e3641ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de episodios de entrenamiento\n",
    "episodes = 100\n",
    "\n",
    "# Bucle de entrenamiento\n",
    "for e in range(episodes):\n",
    "\n",
    "    # Reiniciar el entorno y obtener el estado inicial\n",
    "    state = env.reset()\n",
    "\n",
    "    while True:\n",
    "        # Renderizar el entorno\n",
    "        env.render()\n",
    "\n",
    "        # Elegir una acción con el agente\n",
    "        action = mario.act(state)\n",
    "\n",
    "        # Ejecutar la acción en el entorno\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "\n",
    "        # Almacenar la transición en la memoria del agente\n",
    "        mario.cache(state, next_state, action, reward, done)\n",
    "\n",
    "        # Registrar métricas del paso\n",
    "        logger.log_step(reward, None, None)\n",
    "\n",
    "        # Actualizar el estado actual\n",
    "        state = next_state\n",
    "\n",
    "        # Salir del bucle si el juego termina o Mario alcanza la meta\n",
    "        if done or info['flag_get']:\n",
    "            break\n",
    "\n",
    "    # Registrar métricas del episodio\n",
    "    logger.log_episode()\n",
    "\n",
    "    # Guardar métricas cada 20 episodios\n",
    "    if e % 20 == 0:\n",
    "        logger.record(\n",
    "            episode=e,\n",
    "            epsilon=mario.exploration_rate,\n",
    "            step=mario.curr_step\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mario)",
   "language": "python",
   "name": "mario"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
